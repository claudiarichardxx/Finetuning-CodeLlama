{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "4Rz5HusUrXZv"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30ae90ad4cb84c4eab612b0e0c6957e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d0838619804d2db0cf7f45719c3715",
              "IPY_MODEL_ad0a0bfd19284f4fad14c48aa539ed41",
              "IPY_MODEL_d5ef6c0d5a184cbd8562481734ffb75e"
            ],
            "layout": "IPY_MODEL_afcc32b8a2964f88bf9f46fd98e897b0"
          }
        },
        "11d0838619804d2db0cf7f45719c3715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ef57b8d54e6488b9e8605ed07a62ce7",
            "placeholder": "​",
            "style": "IPY_MODEL_309e5311ca124ce69d07ae10cbfadf25",
            "value": "Loading checkpoint shards:  50%"
          }
        },
        "ad0a0bfd19284f4fad14c48aa539ed41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2756b2cf866d49d5be117298a91b222a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a747096bb9064278a951a9e90905779d",
            "value": 1
          }
        },
        "d5ef6c0d5a184cbd8562481734ffb75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_280308f9043943838f0cafae2adb22a3",
            "placeholder": "​",
            "style": "IPY_MODEL_1e9aa593eb4b4275b27dd6c8f6df05d8",
            "value": " 1/2 [00:57&lt;00:57, 57.76s/it]"
          }
        },
        "afcc32b8a2964f88bf9f46fd98e897b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef57b8d54e6488b9e8605ed07a62ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "309e5311ca124ce69d07ae10cbfadf25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2756b2cf866d49d5be117298a91b222a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a747096bb9064278a951a9e90905779d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "280308f9043943838f0cafae2adb22a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9aa593eb4b4275b27dd6c8f6df05d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ede340d48fc64d349035f62aad8617e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84f1172ead554b209af50242c3282550",
              "IPY_MODEL_1a23dd98b9194bb195040cbc55fe3a29",
              "IPY_MODEL_e8069ad759ee4bca83b23d9e6a46974e"
            ],
            "layout": "IPY_MODEL_3af1d4157c724f82b47b12cf0faa3bfc"
          }
        },
        "84f1172ead554b209af50242c3282550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2817fad5b564b6f98bd3a7621967a82",
            "placeholder": "​",
            "style": "IPY_MODEL_fb92db6d9d3d4fbca7f8681ffcabe924",
            "value": "config.json: 100%"
          }
        },
        "1a23dd98b9194bb195040cbc55fe3a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_460f9e04e64f4c47bc19bf6d41e1a7c6",
            "max": 644,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0626a5c71eb64e91a69e629352d4738b",
            "value": 644
          }
        },
        "e8069ad759ee4bca83b23d9e6a46974e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdeee9bfc294bf0a7115fb2377f80c4",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a97c054a5349f19fd64061f1e07b7c",
            "value": " 644/644 [00:00&lt;00:00, 19.2kB/s]"
          }
        },
        "3af1d4157c724f82b47b12cf0faa3bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2817fad5b564b6f98bd3a7621967a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb92db6d9d3d4fbca7f8681ffcabe924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "460f9e04e64f4c47bc19bf6d41e1a7c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0626a5c71eb64e91a69e629352d4738b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bdeee9bfc294bf0a7115fb2377f80c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a97c054a5349f19fd64061f1e07b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "466d5765da324785b21d379a71bde65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48db1a7b38f747dfbedc01a1d7335227",
              "IPY_MODEL_4650f1e2173845cc90afa45bd6af8bf4",
              "IPY_MODEL_3a0faaf871444558ac5d527df92f9921"
            ],
            "layout": "IPY_MODEL_b780caba06504c9e84383113ec28593c"
          }
        },
        "48db1a7b38f747dfbedc01a1d7335227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc78601bca2e4ac8aa74850d04caafc0",
            "placeholder": "​",
            "style": "IPY_MODEL_1a38c6740c4d45fa86092ba4a96fd418",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "4650f1e2173845cc90afa45bd6af8bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b5e8c4cc7a7412c9f8ad9f1dc9bde4b",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68d4f2d714aa47f69aef80ffe3b601d7",
            "value": 25125
          }
        },
        "3a0faaf871444558ac5d527df92f9921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d5d650fb8d24a858a197537a8cd1081",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd9846576c84517a106e45f3f5aabcb",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 454kB/s]"
          }
        },
        "b780caba06504c9e84383113ec28593c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc78601bca2e4ac8aa74850d04caafc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a38c6740c4d45fa86092ba4a96fd418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b5e8c4cc7a7412c9f8ad9f1dc9bde4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d4f2d714aa47f69aef80ffe3b601d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d5d650fb8d24a858a197537a8cd1081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd9846576c84517a106e45f3f5aabcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23578f26dd77475cbe1e170a535d6521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_384b04d892874880a71c4edeb454d0b1",
              "IPY_MODEL_2b25c91584be47c89ba2fe55db9b2867",
              "IPY_MODEL_9c81beee2ded4931ae64a304d0351243"
            ],
            "layout": "IPY_MODEL_1dd3ecdbb2f14f7f9ca206d58a08b05d"
          }
        },
        "384b04d892874880a71c4edeb454d0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bbf5d317bac452ca82a54cfbf0bb1cc",
            "placeholder": "​",
            "style": "IPY_MODEL_49a4ea02062a44d4845022979816014c",
            "value": "Downloading shards: 100%"
          }
        },
        "2b25c91584be47c89ba2fe55db9b2867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f99452ce595480e8d97e4c1d14e12aa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc0dcb23fb904c2da0a847b2fc6fa1ce",
            "value": 2
          }
        },
        "9c81beee2ded4931ae64a304d0351243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d6d09162fdd471c997e51210742f44b",
            "placeholder": "​",
            "style": "IPY_MODEL_e50d3df8f9354f928a05038fb818f8af",
            "value": " 2/2 [05:49&lt;00:00, 163.00s/it]"
          }
        },
        "1dd3ecdbb2f14f7f9ca206d58a08b05d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bbf5d317bac452ca82a54cfbf0bb1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49a4ea02062a44d4845022979816014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f99452ce595480e8d97e4c1d14e12aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc0dcb23fb904c2da0a847b2fc6fa1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d6d09162fdd471c997e51210742f44b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50d3df8f9354f928a05038fb818f8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98cca9ee46e04095b04a32c51cee2fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7509b5ef7cc04bfba9ec5553c65f101e",
              "IPY_MODEL_40bf81fe498149478ff15c15c56d1f8a",
              "IPY_MODEL_6f59d1cbab2e4063a7db833c72b4a6f4"
            ],
            "layout": "IPY_MODEL_f01b0480d4f84a719c67b3aab42eaee8"
          }
        },
        "7509b5ef7cc04bfba9ec5553c65f101e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0b42f2277c74ac5b95c613ad6130fc7",
            "placeholder": "​",
            "style": "IPY_MODEL_ee842631a7f04f8bb1c52fe142a2cf67",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "40bf81fe498149478ff15c15c56d1f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ce83d634ca44968c85c8730854a16c",
            "max": 9976570520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10b3513a809d4cb795ec5467b9728f0c",
            "value": 9976570520
          }
        },
        "6f59d1cbab2e4063a7db833c72b4a6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f3e53eae864b42961341dc5db46f46",
            "placeholder": "​",
            "style": "IPY_MODEL_06f28881b94545cfbec9ff922f2fa553",
            "value": " 9.98G/9.98G [04:01&lt;00:00, 46.6MB/s]"
          }
        },
        "f01b0480d4f84a719c67b3aab42eaee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b42f2277c74ac5b95c613ad6130fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee842631a7f04f8bb1c52fe142a2cf67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32ce83d634ca44968c85c8730854a16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10b3513a809d4cb795ec5467b9728f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0f3e53eae864b42961341dc5db46f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f28881b94545cfbec9ff922f2fa553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53db465425ea40a686bff69b0ab47d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5194284fe55d4016808667b472412a6f",
              "IPY_MODEL_73fc965377494b1c958c7f26bc9f4b86",
              "IPY_MODEL_ded79f5da9e7460fb09a4b8df0086820"
            ],
            "layout": "IPY_MODEL_a2557edea64447e1ac088ac13b072cc3"
          }
        },
        "5194284fe55d4016808667b472412a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_466b6144ae34431e8b7bba62401f3a4b",
            "placeholder": "​",
            "style": "IPY_MODEL_eb29deeacf524ce7a1aa45339c73fcb2",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "73fc965377494b1c958c7f26bc9f4b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f02f1898a644212a36d85c3e94a799f",
            "max": 3500294544,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7483821165f43f5b2bff88b2d24423f",
            "value": 3500294544
          }
        },
        "ded79f5da9e7460fb09a4b8df0086820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d5d0dbdfbda4bcca9f1e9110afc4804",
            "placeholder": "​",
            "style": "IPY_MODEL_21a1de5fbd494aed9221a961879a2260",
            "value": " 3.50G/3.50G [01:47&lt;00:00, 56.7MB/s]"
          }
        },
        "a2557edea64447e1ac088ac13b072cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "466b6144ae34431e8b7bba62401f3a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb29deeacf524ce7a1aa45339c73fcb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f02f1898a644212a36d85c3e94a799f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7483821165f43f5b2bff88b2d24423f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d5d0dbdfbda4bcca9f1e9110afc4804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21a1de5fbd494aed9221a961879a2260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84eb0d4409204896bd93393119d728d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d2f721328b94d988ad0804088d4eddf",
              "IPY_MODEL_be9562135bf24576b01ac9a70b0c0f0a",
              "IPY_MODEL_f80e3ba2eecd469b810fb85ac0e297b2"
            ],
            "layout": "IPY_MODEL_1e9e13d2a5ec44989608baf5339e833a"
          }
        },
        "2d2f721328b94d988ad0804088d4eddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abce48a2bb744f8284c3fc41097c9eb4",
            "placeholder": "​",
            "style": "IPY_MODEL_2dba7845f04c4ef9b1a4b7d0b93bc9bc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "be9562135bf24576b01ac9a70b0c0f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fef38a5234d4527a54999930643bb9b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20983974428a4db5ad51c18617aad66b",
            "value": 2
          }
        },
        "f80e3ba2eecd469b810fb85ac0e297b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7099fc37bf9d40419614f4a6b77c6094",
            "placeholder": "​",
            "style": "IPY_MODEL_823d54936d954711999735936fce3809",
            "value": " 2/2 [01:11&lt;00:00, 32.44s/it]"
          }
        },
        "1e9e13d2a5ec44989608baf5339e833a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abce48a2bb744f8284c3fc41097c9eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dba7845f04c4ef9b1a4b7d0b93bc9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fef38a5234d4527a54999930643bb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20983974428a4db5ad51c18617aad66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7099fc37bf9d40419614f4a6b77c6094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "823d54936d954711999735936fce3809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "262b24178f384ef386efd692f08974a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ff31a8120d348b092ba66742f7e5ce6",
              "IPY_MODEL_ba274c8b568e42b0a674eb3125e985a6",
              "IPY_MODEL_0fa4a179c7b54b0fbbf3a4cac9e7e427"
            ],
            "layout": "IPY_MODEL_051d363fe0ca4072b323046886180ddd"
          }
        },
        "7ff31a8120d348b092ba66742f7e5ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c25b06a3ff4467aa2a89a780069062",
            "placeholder": "​",
            "style": "IPY_MODEL_fd4e6b72da844fa39f10d62dd7c78561",
            "value": "generation_config.json: 100%"
          }
        },
        "ba274c8b568e42b0a674eb3125e985a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d8f44f99ce42b0a31ffd74820b7135",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b3c3dc17a234ea68f4065048e2435e0",
            "value": 116
          }
        },
        "0fa4a179c7b54b0fbbf3a4cac9e7e427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea8a07a5cf644c429f3f228a83ddd7ed",
            "placeholder": "​",
            "style": "IPY_MODEL_20513183bd794845a5e05e29495159f9",
            "value": " 116/116 [00:00&lt;00:00, 7.20kB/s]"
          }
        },
        "051d363fe0ca4072b323046886180ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c25b06a3ff4467aa2a89a780069062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd4e6b72da844fa39f10d62dd7c78561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3d8f44f99ce42b0a31ffd74820b7135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3c3dc17a234ea68f4065048e2435e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea8a07a5cf644c429f3f228a83ddd7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20513183bd794845a5e05e29495159f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0a7781a1db54ff98f9730c3c9259dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f76d6b47bdd44059b2e56db074ec3891",
              "IPY_MODEL_871234eb85dc46ceaf87d31708f133c8",
              "IPY_MODEL_0d39ef51b8764f44a1fb652fdb5dbb64"
            ],
            "layout": "IPY_MODEL_b12219c2eb1a4529ad6f985f30d9d5c4"
          }
        },
        "f76d6b47bdd44059b2e56db074ec3891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c02c534266945688e933de8bfebc8ae",
            "placeholder": "​",
            "style": "IPY_MODEL_94438b4a305e447f9a0378e3cef433f3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "871234eb85dc46ceaf87d31708f133c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d5709e565c246789c44f27200f2fe92",
            "max": 749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19c4ff8b5aab45b0bdf22a9aa2a4741f",
            "value": 749
          }
        },
        "0d39ef51b8764f44a1fb652fdb5dbb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_144fef21b09f4cb8bb23836b4148544b",
            "placeholder": "​",
            "style": "IPY_MODEL_7f348f75b81349fe99628a6a294dfda0",
            "value": " 749/749 [00:00&lt;00:00, 49.4kB/s]"
          }
        },
        "b12219c2eb1a4529ad6f985f30d9d5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c02c534266945688e933de8bfebc8ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94438b4a305e447f9a0378e3cef433f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d5709e565c246789c44f27200f2fe92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c4ff8b5aab45b0bdf22a9aa2a4741f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "144fef21b09f4cb8bb23836b4148544b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f348f75b81349fe99628a6a294dfda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c2b8fd9e1494bd9b668c2522333f09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fc0915a055e4d958c5f709cfef3a82a",
              "IPY_MODEL_ff65b88987cd4d26af1f1b375da50dba",
              "IPY_MODEL_b6b3ce853bca460ba8e850a8d10faa9d"
            ],
            "layout": "IPY_MODEL_cce52597484544e5afc24b56b3e195d0"
          }
        },
        "0fc0915a055e4d958c5f709cfef3a82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2880bd09da954dcba2a50ca9e6ce57fd",
            "placeholder": "​",
            "style": "IPY_MODEL_196a9a5bcdea4e548b7efc5866fb6a1e",
            "value": "tokenizer.model: 100%"
          }
        },
        "ff65b88987cd4d26af1f1b375da50dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf960886f16c4ad69103b996448a29d7",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_314294f67f58442f84873d0f0a06a8d4",
            "value": 499723
          }
        },
        "b6b3ce853bca460ba8e850a8d10faa9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65423b46bb7b4e64ae2fef4eb75720cb",
            "placeholder": "​",
            "style": "IPY_MODEL_3bd8572d2fc54382bb7940cbcfe45b07",
            "value": " 500k/500k [00:00&lt;00:00, 2.39MB/s]"
          }
        },
        "cce52597484544e5afc24b56b3e195d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2880bd09da954dcba2a50ca9e6ce57fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "196a9a5bcdea4e548b7efc5866fb6a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf960886f16c4ad69103b996448a29d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314294f67f58442f84873d0f0a06a8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65423b46bb7b4e64ae2fef4eb75720cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd8572d2fc54382bb7940cbcfe45b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aeeda11fdbe49a4aee36b81dcd572c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72ddaaeed0804bcabf40f848243102a0",
              "IPY_MODEL_978f3fd71b4945ab9240c8f8cc178bbc",
              "IPY_MODEL_01e5726aea3544e39e7aaf2d7b53069b"
            ],
            "layout": "IPY_MODEL_9bbe2a9d5f194b8aba289e97376f10d2"
          }
        },
        "72ddaaeed0804bcabf40f848243102a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dcf2ab9a8b74368af3b0ee04206e4f3",
            "placeholder": "​",
            "style": "IPY_MODEL_a366ebcf65c140f5b959dd5ce16d4f7d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "978f3fd71b4945ab9240c8f8cc178bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aace17b2b804a2d95c6d8a7d5eafd10",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_155652fae3234313806b326dda93cfe6",
            "value": 411
          }
        },
        "01e5726aea3544e39e7aaf2d7b53069b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87c18707fede431f94478efed6fb0406",
            "placeholder": "​",
            "style": "IPY_MODEL_aa801b882a6f4845b60a840ad53298dc",
            "value": " 411/411 [00:00&lt;00:00, 30.9kB/s]"
          }
        },
        "9bbe2a9d5f194b8aba289e97376f10d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dcf2ab9a8b74368af3b0ee04206e4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a366ebcf65c140f5b959dd5ce16d4f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aace17b2b804a2d95c6d8a7d5eafd10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155652fae3234313806b326dda93cfe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87c18707fede431f94478efed6fb0406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa801b882a6f4845b60a840ad53298dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ada9f91bae614c54995044bc3bd752d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4699fd52a9b544c6b71f16562d611cf5",
              "IPY_MODEL_272c51b4a4794c0fbb19bd5978e8795b",
              "IPY_MODEL_04138f5a39a24d58906c36298cc24ca6"
            ],
            "layout": "IPY_MODEL_70a12257d51143e5a00f1a6385dc04ec"
          }
        },
        "4699fd52a9b544c6b71f16562d611cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0f60abf25f41728b8440cc76621ecf",
            "placeholder": "​",
            "style": "IPY_MODEL_efb44604de39478bb6cd2eacc37e4478",
            "value": "tokenizer.json: 100%"
          }
        },
        "272c51b4a4794c0fbb19bd5978e8795b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fccb1ce52734459a058f664a82545e4",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9293501cb4b4ac28652bcd15445c4a1",
            "value": 1842767
          }
        },
        "04138f5a39a24d58906c36298cc24ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf12a2e40cb423e9c2a8361990ba745",
            "placeholder": "​",
            "style": "IPY_MODEL_a9cdb72aad3246adaf06fc4be676848b",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 4.45MB/s]"
          }
        },
        "70a12257d51143e5a00f1a6385dc04ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0f60abf25f41728b8440cc76621ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb44604de39478bb6cd2eacc37e4478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fccb1ce52734459a058f664a82545e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9293501cb4b4ac28652bcd15445c4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acf12a2e40cb423e9c2a8361990ba745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9cdb72aad3246adaf06fc4be676848b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiarichardxx/Finetuning-CodeLlama/blob/main/Finetuning_Codellama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "**Code Llama** is a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. (Taken from the abstract of the paper : [Code Llama: Open Foundation Models for Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/))\n",
        "\n",
        "This colab demos how to\n",
        "\n",
        "* Load Code Llama\n",
        "* Evaluate Code Llama\n",
        "* FineTune Code Llama"
      ],
      "metadata": {
        "id": "EgkTSbc-FdNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning the GitHub repository 'claudiarichardxx/Finetuning-CodeLlama' to download the data"
      ],
      "metadata": {
        "id": "HUGBxQlP4nPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/claudiarichardxx/Finetuning-CodeLlama.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPwpvGsyQpU1",
        "outputId": "361a75c4-4bc4-4583-96d8-f5ccb9b06f30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Finetuning-CodeLlama'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 174 (delta 88), reused 111 (delta 39), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (174/174), 4.89 MiB | 6.72 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Finetuning-CodeLlama/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx6HQy9Wa-B9",
        "outputId": "d72cb9d9-3a6d-4266-b4e7-e80fd3449333"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Finetuning-CodeLlama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning Setup"
      ],
      "metadata": {
        "id": "VvDmJBdGXTO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations\n",
        "\n",
        "We first install the libraries:\n",
        "\n",
        "* `accelerate`: The accelerate library is designed to make it easier to run models on GPUs and distributed environments, helping with performance optimization and scaling.\n",
        "\n",
        "* `peft`: The peft library stands for \"parameter-efficient fine-tuning,\" which is useful for adapting pre-trained models with fewer parameters, making the fine-tuning process more efficient.\n",
        "\n",
        "* `bitsandbytes`: The bitsandbytes library provides 4 and 8-bit optimizers and matrix multiplication routines, allowing for more memory-efficient training of LLMs.\n",
        "\n",
        "* `transformers`: The transformers library by Hugging Face provides state-of-the-art implementations of transformer models (like BERT, GPT, T5, etc.), allowing easy model loading, training, and deployment.\n",
        "\n",
        "* `trl`: The trl library (Transformers Reinforcement Learning) integrates reinforcement learning algorithms with transformer models, allowing for fine-tuning of language models using RL techniques.\n",
        "\n",
        "* `tqdm` and `fire` are required to run the evaluation on HumanEval as mentioned in the GitHub repository.\n"
      ],
      "metadata": {
        "id": "Lruis8yBHCuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q accelerate==0.27.2 peft==0.5.0 bitsandbytes==0.41.3 transformers==4.38.2 trl==0.4.7\n",
        "! pip install -q protobuf sentencepiece scipy\n",
        "! pip install tqdm fire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwa7lxyRQ7bi",
        "outputId": "071d9d0e-446a-4232-e502-6c633f139e5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Collecting fire\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.5.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=808bd1f5e1958fa8cc352616079e2cec4349f409448a4c520b587bd34f8d367b\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some helper functions"
      ],
      "metadata": {
        "id": "4Rz5HusUrXZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`json`: Used to parse JSON data into Python objects and write Python objects back to JSON format.\n",
        "\n",
        "`os`: Provides functions to interact with the operating system, like handling file paths and checking if files exist.\n",
        "\n",
        "`io`: Provides tools to work with file-like objects (both in-memory and actual files). It helps handle file streams more flexibly."
      ],
      "metadata": {
        "id": "HXakjAZkSEt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import io"
      ],
      "metadata": {
        "id": "KBerDsQmlw0h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function loads a .json file and converts it into a Python dictionary. It takes the file path f and a file access mode (default is \"r\" for read mode)"
      ],
      "metadata": {
        "id": "IWGuwSc7RdwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jload(f, mode=\"r\"):\n",
        "\n",
        "    \"\"\"Load a .json file into a dictionary.\"\"\"\n",
        "\n",
        "    f = _make_r_io_base(f, mode)\n",
        "    jdict = json.load(f)\n",
        "    f.close()\n",
        "\n",
        "    return jdict"
      ],
      "metadata": {
        "id": "tqtEVRnllmsl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helper function ensures that the input f is a file object. If f is not already a file object (i.e., if it’s a string representing a file path), the function opens the file with the given mode."
      ],
      "metadata": {
        "id": "ogtiDQ1CRme4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _make_r_io_base(f, mode: str):\n",
        "\n",
        "    if not isinstance(f, io.IOBase):\n",
        "        f = open(f, mode=mode)\n",
        "\n",
        "    return f"
      ],
      "metadata": {
        "id": "UHUgEnO-lsdV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction Tuning"
      ],
      "metadata": {
        "id": "sufvqz2Lrbqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: [CodeAlpaca](https://github.com/sahil280114/codealpaca.git)"
      ],
      "metadata": {
        "id": "HrXZyG5Oh1pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load the model and tokenizer"
      ],
      "metadata": {
        "id": "85V-vRRDXGJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`CodeLlamaTokenizer, LlamaForCausalLM, BitsAndBytesConfig`: Necessary classes from Hugging Face’s transformers library. This helps in loading the tokenizer and model (Llama) and configuring model quantization with BitsAndBytes for efficient loading.\n",
        "\n",
        "`torch`: PyTorch, the core library used for tensor operations and model handling."
      ],
      "metadata": {
        "id": "NaX7QFqoS8EM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CodeLlamaTokenizer, LlamaForCausalLM, BitsAndBytesConfig\n",
        "import torch"
      ],
      "metadata": {
        "id": "m4Zp4ADf3noC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line sets the name of the model to be loaded. It will be used later to initialize both the model and tokenizer from Hugging Face's model hub."
      ],
      "metadata": {
        "id": "mN2dHdFhTS8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'codellama/CodeLlama-7b-Python-hf'"
      ],
      "metadata": {
        "id": "MG5M1z4HWI4q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we set up the configuration for loading our model efficiently:\n",
        "\n",
        "`use_4bit = True`: We're opting to use 4-bit quantization to reduce memory usage and speed up inference. It's a trade-off between precision and resource efficiency.\n",
        "\n",
        "`bnb_4bit_compute_dtype = \"float16\"`: We specify that calculations will be done in 16-bit floating point format, which helps in saving GPU memory while still providing decent accuracy.\n",
        "\n",
        "`bnb_4bit_quant_type = \"nf4\"`: This sets the quantization type to \"nf4\", which is a specific way to represent our model weights that helps further optimize performance.\n",
        "\n",
        "`use_nested_quant = False`: We're not using nested quantization here.\n",
        "\n",
        "`compute_dtype = getattr(torch, bnb_4bit_compute_dtype)`: This line retrieves the float16 type from the PyTorch library so we can use it in our configuration.\n",
        "\n",
        "`bnb_config = BitsAndBytesConfig(...)`: Finally, we create a configuration object for the BitsAndBytes setup, passing in all the parameters we've defined. This will guide how our model is loaded and optimized."
      ],
      "metadata": {
        "id": "d3mhQzciT-qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_4bit = True\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "use_nested_quant = False\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "                load_in_4bit = use_4bit,\n",
        "                bnb_4bit_quant_type = bnb_4bit_quant_type,\n",
        "                bnb_4bit_compute_dtype = compute_dtype,\n",
        "                bnb_4bit_use_double_quant=use_nested_quant,\n",
        "            )"
      ],
      "metadata": {
        "id": "L1yM2NUBWMKF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we're loading the model and tokenizer based on our earlier setup:\n",
        "\n",
        "**Loading the Model:**\n",
        "\n",
        "- If `use_4bit` is `True`, we load the model with 4-bit quantization by passing the `bnb_config`.\n",
        "- If `use_4bit` is `False`, we simply load the model without quantization, still ensuring it runs efficiently on the available hardware by setting `device_map='auto'`.\n",
        "\n",
        "**Loading the Tokenizer:**\n",
        "\n",
        "- We then load the tokenizer using `CodeLlamaTokenizer.from_pretrained(model_name)`. The `padding_side=\"right\"` option specifies how to handle padding when processing sequences, while `use_fast=False` means we're opting for a standard implementation instead of a faster version that requires additional dependencies."
      ],
      "metadata": {
        "id": "DL9XuEfVVDDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (use_4bit):\n",
        "            model = LlamaForCausalLM.from_pretrained(\n",
        "                    model_name,\n",
        "                    quantization_config=bnb_config,\n",
        "                    device_map='auto')\n",
        "\n",
        "else:\n",
        "            model = LlamaForCausalLM.from_pretrained(\n",
        "                    model_name,\n",
        "                    device_map='auto')\n",
        "\n",
        "\n",
        "tokenizer = CodeLlamaTokenizer.from_pretrained(\n",
        "                model_name,\n",
        "                padding_side = \"right\",\n",
        "                use_fast=False,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563,
          "referenced_widgets": [
            "ede340d48fc64d349035f62aad8617e8",
            "84f1172ead554b209af50242c3282550",
            "1a23dd98b9194bb195040cbc55fe3a29",
            "e8069ad759ee4bca83b23d9e6a46974e",
            "3af1d4157c724f82b47b12cf0faa3bfc",
            "e2817fad5b564b6f98bd3a7621967a82",
            "fb92db6d9d3d4fbca7f8681ffcabe924",
            "460f9e04e64f4c47bc19bf6d41e1a7c6",
            "0626a5c71eb64e91a69e629352d4738b",
            "0bdeee9bfc294bf0a7115fb2377f80c4",
            "f9a97c054a5349f19fd64061f1e07b7c",
            "466d5765da324785b21d379a71bde65b",
            "48db1a7b38f747dfbedc01a1d7335227",
            "4650f1e2173845cc90afa45bd6af8bf4",
            "3a0faaf871444558ac5d527df92f9921",
            "b780caba06504c9e84383113ec28593c",
            "dc78601bca2e4ac8aa74850d04caafc0",
            "1a38c6740c4d45fa86092ba4a96fd418",
            "4b5e8c4cc7a7412c9f8ad9f1dc9bde4b",
            "68d4f2d714aa47f69aef80ffe3b601d7",
            "3d5d650fb8d24a858a197537a8cd1081",
            "0bd9846576c84517a106e45f3f5aabcb",
            "23578f26dd77475cbe1e170a535d6521",
            "384b04d892874880a71c4edeb454d0b1",
            "2b25c91584be47c89ba2fe55db9b2867",
            "9c81beee2ded4931ae64a304d0351243",
            "1dd3ecdbb2f14f7f9ca206d58a08b05d",
            "8bbf5d317bac452ca82a54cfbf0bb1cc",
            "49a4ea02062a44d4845022979816014c",
            "3f99452ce595480e8d97e4c1d14e12aa",
            "dc0dcb23fb904c2da0a847b2fc6fa1ce",
            "6d6d09162fdd471c997e51210742f44b",
            "e50d3df8f9354f928a05038fb818f8af",
            "98cca9ee46e04095b04a32c51cee2fc6",
            "7509b5ef7cc04bfba9ec5553c65f101e",
            "40bf81fe498149478ff15c15c56d1f8a",
            "6f59d1cbab2e4063a7db833c72b4a6f4",
            "f01b0480d4f84a719c67b3aab42eaee8",
            "f0b42f2277c74ac5b95c613ad6130fc7",
            "ee842631a7f04f8bb1c52fe142a2cf67",
            "32ce83d634ca44968c85c8730854a16c",
            "10b3513a809d4cb795ec5467b9728f0c",
            "a0f3e53eae864b42961341dc5db46f46",
            "06f28881b94545cfbec9ff922f2fa553",
            "53db465425ea40a686bff69b0ab47d31",
            "5194284fe55d4016808667b472412a6f",
            "73fc965377494b1c958c7f26bc9f4b86",
            "ded79f5da9e7460fb09a4b8df0086820",
            "a2557edea64447e1ac088ac13b072cc3",
            "466b6144ae34431e8b7bba62401f3a4b",
            "eb29deeacf524ce7a1aa45339c73fcb2",
            "6f02f1898a644212a36d85c3e94a799f",
            "c7483821165f43f5b2bff88b2d24423f",
            "2d5d0dbdfbda4bcca9f1e9110afc4804",
            "21a1de5fbd494aed9221a961879a2260",
            "84eb0d4409204896bd93393119d728d0",
            "2d2f721328b94d988ad0804088d4eddf",
            "be9562135bf24576b01ac9a70b0c0f0a",
            "f80e3ba2eecd469b810fb85ac0e297b2",
            "1e9e13d2a5ec44989608baf5339e833a",
            "abce48a2bb744f8284c3fc41097c9eb4",
            "2dba7845f04c4ef9b1a4b7d0b93bc9bc",
            "1fef38a5234d4527a54999930643bb9b",
            "20983974428a4db5ad51c18617aad66b",
            "7099fc37bf9d40419614f4a6b77c6094",
            "823d54936d954711999735936fce3809",
            "262b24178f384ef386efd692f08974a2",
            "7ff31a8120d348b092ba66742f7e5ce6",
            "ba274c8b568e42b0a674eb3125e985a6",
            "0fa4a179c7b54b0fbbf3a4cac9e7e427",
            "051d363fe0ca4072b323046886180ddd",
            "d6c25b06a3ff4467aa2a89a780069062",
            "fd4e6b72da844fa39f10d62dd7c78561",
            "b3d8f44f99ce42b0a31ffd74820b7135",
            "0b3c3dc17a234ea68f4065048e2435e0",
            "ea8a07a5cf644c429f3f228a83ddd7ed",
            "20513183bd794845a5e05e29495159f9",
            "e0a7781a1db54ff98f9730c3c9259dac",
            "f76d6b47bdd44059b2e56db074ec3891",
            "871234eb85dc46ceaf87d31708f133c8",
            "0d39ef51b8764f44a1fb652fdb5dbb64",
            "b12219c2eb1a4529ad6f985f30d9d5c4",
            "9c02c534266945688e933de8bfebc8ae",
            "94438b4a305e447f9a0378e3cef433f3",
            "2d5709e565c246789c44f27200f2fe92",
            "19c4ff8b5aab45b0bdf22a9aa2a4741f",
            "144fef21b09f4cb8bb23836b4148544b",
            "7f348f75b81349fe99628a6a294dfda0",
            "5c2b8fd9e1494bd9b668c2522333f09b",
            "0fc0915a055e4d958c5f709cfef3a82a",
            "ff65b88987cd4d26af1f1b375da50dba",
            "b6b3ce853bca460ba8e850a8d10faa9d",
            "cce52597484544e5afc24b56b3e195d0",
            "2880bd09da954dcba2a50ca9e6ce57fd",
            "196a9a5bcdea4e548b7efc5866fb6a1e",
            "cf960886f16c4ad69103b996448a29d7",
            "314294f67f58442f84873d0f0a06a8d4",
            "65423b46bb7b4e64ae2fef4eb75720cb",
            "3bd8572d2fc54382bb7940cbcfe45b07",
            "7aeeda11fdbe49a4aee36b81dcd572c4",
            "72ddaaeed0804bcabf40f848243102a0",
            "978f3fd71b4945ab9240c8f8cc178bbc",
            "01e5726aea3544e39e7aaf2d7b53069b",
            "9bbe2a9d5f194b8aba289e97376f10d2",
            "3dcf2ab9a8b74368af3b0ee04206e4f3",
            "a366ebcf65c140f5b959dd5ce16d4f7d",
            "2aace17b2b804a2d95c6d8a7d5eafd10",
            "155652fae3234313806b326dda93cfe6",
            "87c18707fede431f94478efed6fb0406",
            "aa801b882a6f4845b60a840ad53298dc",
            "ada9f91bae614c54995044bc3bd752d5",
            "4699fd52a9b544c6b71f16562d611cf5",
            "272c51b4a4794c0fbb19bd5978e8795b",
            "04138f5a39a24d58906c36298cc24ca6",
            "70a12257d51143e5a00f1a6385dc04ec",
            "6f0f60abf25f41728b8440cc76621ecf",
            "efb44604de39478bb6cd2eacc37e4478",
            "9fccb1ce52734459a058f664a82545e4",
            "d9293501cb4b4ac28652bcd15445c4a1",
            "acf12a2e40cb423e9c2a8361990ba745",
            "a9cdb72aad3246adaf06fc4be676848b"
          ]
        },
        "id": "V0r4fZ9F2iQ3",
        "outputId": "777e8a7b-0176-4a01-bdeb-da58e7b5fa16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ede340d48fc64d349035f62aad8617e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "466d5765da324785b21d379a71bde65b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23578f26dd77475cbe1e170a535d6521"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98cca9ee46e04095b04a32c51cee2fc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53db465425ea40a686bff69b0ab47d31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84eb0d4409204896bd93393119d728d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "262b24178f384ef386efd692f08974a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0a7781a1db54ff98f9730c3c9259dac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c2b8fd9e1494bd9b668c2522333f09b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aeeda11fdbe49a4aee36b81dcd572c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ada9f91bae614c54995044bc3bd752d5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we define some default tokens used in our model:\n",
        "\n",
        "- `DEFAULT_PAD_TOKEN`: This is set to `\"[PAD]\"`, which is used to pad sequences to ensure they have the same length during training or inference.\n",
        "  \n",
        "- `DEFAULT_EOS_TOKEN`: The end-of-sequence token is set to `\"</s>\"`. This token indicates the end of a sequence, helping the model understand when to stop generating text.\n",
        "\n",
        "- `DEFAULT_BOS_TOKEN`: The beginning-of-sequence token is also set to `\"</s>\"`. This token is used to signal the start of a sequence, allowing the model to recognize when it should begin processing input.\n",
        "\n",
        "- `DEFAULT_UNK_TOKEN`: The unknown token is set to `\"</s>\"`. This token represents any word that is not in the model's vocabulary, helping the model handle unseen words during text processing.\n",
        "\n",
        "These tokens are essential for managing input and output sequences effectively in natural language processing tasks."
      ],
      "metadata": {
        "id": "rft6EVRBVfA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "DEFAULT_UNK_TOKEN = \"</s>\""
      ],
      "metadata": {
        "id": "qXauuOUa3lDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function helps integrate new special tokens into a tokenizer and adjusts the model's embeddings accordingly.\n",
        "\n",
        "The function starts by adding the new special tokens to the tokenizer. It keeps track of how many new tokens are added.\n",
        "Then, it resizes the model's token embeddings to match the total number of tokens in the updated tokenizer.\n",
        "If any new tokens were added, it **averages the existing input and output embeddings** (excluding the new tokens) to initialize the embeddings for the new tokens. This helps maintain consistency in how the model handles the input and output data."
      ],
      "metadata": {
        "id": "yJ00E8a3V4KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smart_tokenizer_and_embedding_resize(\n",
        "            special_tokens_dict,\n",
        "            tokenizer,\n",
        "            model,\n",
        "        ):\n",
        "            \"\"\"\n",
        "            Resize the tokenizer and adjust model embeddings to include new special tokens.\n",
        "\n",
        "            Input arguments:\n",
        "                special_tokens_dict (dict):\n",
        "                    A dictionary containing the special tokens (e.g., `pad_token`, `bos_token`, `eos_token`) to add to the tokenizer.\n",
        "\n",
        "                tokenizer (PreTrainedTokenizer):\n",
        "                    The tokenizer whose vocabulary will be resized to include new special tokens.\n",
        "\n",
        "                model (PreTrainedModel):\n",
        "                    The model whose input and output embeddings will be resized to match the new tokenizer size.\n",
        "\n",
        "            Returns:\n",
        "                None:\n",
        "                    This function modifies the `tokenizer` and `model` in-place and does not return any value.\n",
        "\n",
        "            Note: This is the unoptimized version that may make your embedding size not be divisible by 64.\n",
        "            \"\"\"\n",
        "\n",
        "            num_new_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "            model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "            if num_new_tokens > 0:\n",
        "\n",
        "                input_embeddings = model.get_input_embeddings().weight.data\n",
        "                output_embeddings = model.get_output_embeddings().weight.data\n",
        "\n",
        "                input_embeddings_avg = input_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
        "                output_embeddings_avg = output_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
        "\n",
        "                input_embeddings[-num_new_tokens:] = input_embeddings_avg\n",
        "                output_embeddings[-num_new_tokens:] = output_embeddings_avg"
      ],
      "metadata": {
        "id": "ENavntzj3z4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code checks if the tokenizer's padding token is set; if not, it calls the `smart_tokenizer_and_embedding_resize` function to add a default padding token (`DEFAULT_PAD_TOKEN`) and resize the model's embeddings accordingly. After ensuring the padding token is in place, it adds additional special tokens, such as the end-of-sequence, beginning-of-sequence, and unknown tokens, using `tokenizer.add_special_tokens(...)`. This process ensures the tokenizer is fully equipped with the necessary special tokens, allowing the model to handle various tasks effectively."
      ],
      "metadata": {
        "id": "bn2a5J0WWk26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token is None:\n",
        "                    smart_tokenizer_and_embedding_resize(\n",
        "                    special_tokens_dict = dict(pad_token=DEFAULT_PAD_TOKEN),\n",
        "                    tokenizer = tokenizer,\n",
        "                    model = model\n",
        "                )\n",
        "\n",
        "tokenizer.add_special_tokens(\n",
        "            {\n",
        "                \"eos_token\": DEFAULT_EOS_TOKEN,\n",
        "                \"bos_token\": DEFAULT_BOS_TOKEN,\n",
        "                \"unk_token\": DEFAULT_UNK_TOKEN,\n",
        "            })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jbslAAH3WnU",
        "outputId": "681e81b3-e2e2-4435-d48a-faba04efaed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Define the prompt and process the training dataset\n",
        "\n",
        "Here is a short and simple explanation of each import:\n",
        "\n",
        "- `import torch`: Imports the PyTorch library, which is used for tensor operations and building machine learning models.\n",
        "  \n",
        "- `from torch.utils.data import Dataset`: Imports `Dataset`, a class in PyTorch for creating custom datasets to be used in data loading and training.\n",
        "\n",
        "- `from dataclasses import dataclass, field`: Imports `dataclass` and `field` from the `dataclasses` module, which are used to create simple classes for storing data with minimal boilerplate code.\n",
        "\n",
        "- `import copy`: Imports the `copy` module, which provides functions to create shallow or deep copies of objects, useful when you need to duplicate an object without affecting the original."
      ],
      "metadata": {
        "id": "Zn6kWWlKvufy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from dataclasses import dataclass, field\n",
        "import copy"
      ],
      "metadata": {
        "id": "wqaJZKZpSj6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this setup, we determine which prompt template to use based on the presence of an input field in the training set. If the training data includes an input field, the `prompt_input` template is utilized, which combines the instruction with the input context to generate a more comprehensive response. If the training set lacks an input field, the simpler `prompt_no_input` template is applied, focusing solely on the instruction. This approach ensures that the model receives appropriately structured prompts tailored to the available data, facilitating more effective training and response generation.\n",
        "\n",
        "The IGNORE_INDEX is set to -100, which is used to specify tokens that should be ignored during loss calculations in model training."
      ],
      "metadata": {
        "id": "4FvDmiMIXUMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IGNORE_INDEX = -100\n",
        "\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
        "    ),\n",
        "\n",
        "    \"prompt_no_input\": (\n",
        "        \"Below is an instruction that describes a task. \"\n",
        "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "AhFSOvVQ_dwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `DataCollatorForSupervisedDataset` class is a data collator for preparing batches of data during supervised fine-tuning. It's defined using `@dataclass` and takes a tokenizer as an input. The `__call__` method processes a batch of instances, where each instance is a dictionary containing `input_ids` and `labels`. It extracts these values from the instances and pads them to the same length, using the tokenizer's padding token for `input_ids` and `IGNORE_INDEX` (set to `-100`) for the labels. Additionally, an attention mask is created to distinguish between real tokens (marked with 1) and padding tokens (marked with 0). The method returns a dictionary containing the padded `input_ids`, `labels`, and the `attention_mask`."
      ],
      "metadata": {
        "id": "O-3rgoevPh5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DataCollatorForSupervisedDataset(object):\n",
        "\n",
        "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
        "    tokenizer: object\n",
        "\n",
        "    def __call__(self, instances):\n",
        "\n",
        "            \"\"\"\n",
        "            Processes a batch of instances for supervised fine-tuning.\n",
        "\n",
        "            Input arguments:\n",
        "                instances (list of dict):\n",
        "                    A list of dictionaries where each dictionary contains the following keys:\n",
        "                    - 'input_ids': Tensor of input IDs.\n",
        "                    - 'labels': Tensor of corresponding labels.\n",
        "\n",
        "            What it does:\n",
        "                    - Extracts input IDs and labels from the provided instances.\n",
        "                    - Pads the input IDs and labels to the same length using the tokenizer's padding token for input IDs and a predefined constant for labels.\n",
        "                    - Constructs  an attention mask to identify real tokens (not padding) in the input IDs.\n",
        "\n",
        "            Returns:\n",
        "                dict:\n",
        "                    A dictionary containing:\n",
        "                    - 'input_ids': A tensor of padded input IDs.\n",
        "                    - 'labels': A tensor of padded labels.\n",
        "                    - 'attention_mask': A tensor indicating the presence of real tokens (1) and padding (0).\n",
        "            \"\"\"\n",
        "\n",
        "            input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
        "            input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "                input_ids, batch_first=True, padding_value = tokenizer.pad_token_id\n",
        "            )\n",
        "            labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first = True, padding_value = IGNORE_INDEX)\n",
        "            return dict(\n",
        "                input_ids = input_ids,\n",
        "                labels = labels,\n",
        "                attention_mask = input_ids.ne(tokenizer.pad_token_id),\n",
        "            )"
      ],
      "metadata": {
        "id": "c6E1OUJIPfNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Change the source and target according to the mode"
      ],
      "metadata": {
        "id": "c7gugL0jqduf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `SupervisedDataset` class is a custom dataset class for supervised fine-tuning. It loads data from a JSON file, formats input-output pairs using the predefined `PROMPT_DICT`, and tokenizes them with a provided tokenizer.\n",
        "\n",
        "The `preprocess` method tokenizes both the sources and targets, adjusting the labels based on the mode ('IT' for Instruction Tuning or 'IM' for Instruction Modelling). In 'IT' mode, parts of the labels corresponding to the input text are replaced with `IGNORE_INDEX`, which is set to `-100`, so they are ignored during loss calculation. Tokenized data is stored as `input_ids` and `labels`.\n",
        "\n",
        "The `__len__` method returns the number of examples, and `__getitem__` retrieves the input IDs and labels for a given index."
      ],
      "metadata": {
        "id": "6pBathv9hg95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SupervisedDataset(Dataset):\n",
        "\n",
        "        \"\"\"Dataset for supervised fine-tuning.\"\"\"\n",
        "\n",
        "        def preprocess(\n",
        "            self, sources, targets, tokenizer, mode = 'IT'\n",
        "        ):\n",
        "\n",
        "            \"\"\"\n",
        "            Preprocess the data by tokenizing.\n",
        "\n",
        "            Input arguments:\n",
        "                sources (list of str):\n",
        "                    The source texts to be tokenized.\n",
        "                targets (list of str):\n",
        "                    The target texts corresponding to the sources.\n",
        "                tokenizer (Tokenizer):\n",
        "                    The tokenizer used for converting text to input IDs.\n",
        "                mode (str, optional):\n",
        "                    The mode of operation for the preprocessing (default is 'IT' for Instruction Tuning). Options are IT or IM (Instruction Modelling).\n",
        "\n",
        "            What it does:\n",
        "                - Combines the source and target texts into a single list of examples.\n",
        "                - Tokenizes the combined examples and the source texts using the provided tokenizer.\n",
        "                - Creates input IDs from the tokenized examples and initializes labels based on the input IDs.\n",
        "                - In 'IT' mode, replaces the parts of labels that correspond to source lengths with the `IGNORE_INDEX` token.\n",
        "                - Returns a dictionary containing the input IDs and labels.\n",
        "\n",
        "            Returns:\n",
        "                dict: A dictionary containing:\n",
        "                    - input_ids: The tokenized input IDs.\n",
        "                    - labels: The tokenized labels (targets), modified for 'IT' or 'IM' mode.\n",
        "            \"\"\"\n",
        "\n",
        "            examples = [s + t for s, t in zip(sources, targets)]\n",
        "\n",
        "            examples_tokenized, sources_tokenized = [_tokenize_fn(strings, tokenizer) for strings in (examples, sources)]\n",
        "            input_ids = examples_tokenized[\"input_ids\"]\n",
        "            labels = copy.deepcopy(input_ids)\n",
        "\n",
        "            if(mode == 'IT'):\n",
        "\n",
        "                for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
        "                    label[:source_len] = IGNORE_INDEX\n",
        "\n",
        "                return dict(input_ids=input_ids, labels=labels)\n",
        "\n",
        "            else:\n",
        "\n",
        "                return dict(input_ids=input_ids, labels=labels)\n",
        "\n",
        "\n",
        "        def __init__(self, data_path, tokenizer, mode = 'IT'):\n",
        "\n",
        "            \"\"\"\n",
        "            Initializes the SupervisedDataset instance by loading and processing the data.\n",
        "\n",
        "            Input arguments:\n",
        "                data_path (str):\n",
        "                    The path to the JSON file containing the dataset.\n",
        "                tokenizer (Tokenizer):\n",
        "                    The tokenizer used for converting text to input IDs.\n",
        "                mode (str, optional):\n",
        "                    The mode of operation for the dataset (default is 'IT' for Instruction Tuning). Options are IT or IM (Instruction Modelling).\n",
        "\n",
        "            What it does:\n",
        "                - Loads the data from the specified JSON file.\n",
        "                - Formats the input prompts based on the contents of the data.\n",
        "                - Constructs source texts by applying appropriate formatting from PROMPT_DICT.\n",
        "                - Constructs target texts by appending the tokenizer's end-of-sequence token to the outputs.\n",
        "                - Calls the preprocess method to tokenize the sources and targets.\n",
        "                - Initializes input_ids and labels attributes with the processed data.\n",
        "\n",
        "            Returns:\n",
        "                None\n",
        "            \"\"\"\n",
        "\n",
        "            super(SupervisedDataset, self).__init__()\n",
        "            print(\"Loading data...\")\n",
        "            list_data_dict = jload(data_path)\n",
        "\n",
        "            print(\"Formatting inputs...\")\n",
        "            prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
        "            sources = [\n",
        "                prompt_input.format_map(example) if example.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(example)\n",
        "                for example in list_data_dict\n",
        "            ]\n",
        "            targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]\n",
        "\n",
        "            print(\"Tokenizing inputs... This may take some time...\")\n",
        "            data_dict = self.preprocess(sources, targets, tokenizer, mode = mode)\n",
        "\n",
        "            self.input_ids = data_dict[\"input_ids\"]\n",
        "            self.labels = data_dict[\"labels\"]\n",
        "\n",
        "        def __len__(self):\n",
        "\n",
        "            \"\"\"\n",
        "            Returns the number of examples in the dataset.\n",
        "\n",
        "            Input arguments:\n",
        "                None\n",
        "\n",
        "            What it does:\n",
        "                - Calculates the length of the dataset by return`ing the number of input IDs.\n",
        "\n",
        "            Returns:\n",
        "                int:\n",
        "                    The number of examples in the dataset, which is equal to the length of the input_ids attribute.\n",
        "            \"\"\"\n",
        "\n",
        "            return len(self.input_ids)\n",
        "\n",
        "        def __getitem__(self, i):\n",
        "\n",
        "            \"\"\"\n",
        "            Retrieves a single example from the dataset.\n",
        "\n",
        "            Input arguments:\n",
        "                i (int):\n",
        "                    The index of the example to retrieve.\n",
        "\n",
        "            What it does:\n",
        "                - Returns a dictionary containing the input IDs and labels for the specified index.\n",
        "\n",
        "            Returns:\n",
        "                dict:\n",
        "                    A dictionary with the following keys:\n",
        "                    - 'input_ids': The input IDs corresponding to the specified index.\n",
        "                    - 'labels': The labels corresponding to the specified index.\n",
        "            \"\"\"\n",
        "\n",
        "            return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
      ],
      "metadata": {
        "id": "ve0_iV0y2UzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `make_supervised_data_module` function is designed to create a dataset and data collator specifically for supervised fine-tuning of a model. It takes three input arguments: `data_path`, which specifies where the training data is located; `tokenizer`, which is responsible for converting the raw input into tokens suitable for the model; and an optional `mode`, defaulting to 'IT' for Instruction Tuning.\n",
        "\n",
        "The function performs the following steps: it initializes a `SupervisedDataset` object with the provided parameters, which prepares the training data for use. It then creates a `DataCollatorForSupervisedDataset` using the same tokenizer, which helps batch the data appropriately during training. Finally, the function returns a dictionary containing the initialized training dataset, an evaluation dataset (set to `None`), and the data collator, allowing for seamless integration into the training pipeline. This setup ensures that the model is trained effectively on the provided data while accommodating specific requirements based on the dataset's structure.\n"
      ],
      "metadata": {
        "id": "xamsPFI4Thfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_supervised_data_module( data_path, tokenizer, mode = 'IT'):\n",
        "\n",
        "        \"\"\"\n",
        "        Create a dataset and data collator for supervised fine-tuning.\n",
        "\n",
        "        Input arguments:\n",
        "            data_path (str):\n",
        "                The path to the dataset file or directory containing the training data.\n",
        "            tokenizer (Tokenizer):\n",
        "                The tokenizer to be used for tokenizing the input data.\n",
        "            mode (str, optional):\n",
        "                The mode of operation for the dataset, default is 'IT' (Instruction Tuning).\n",
        "\n",
        "        What it does:\n",
        "                - Initializes a `SupervisedDataset` using the provided `data_path`, `tokenizer`, and `mode`.\n",
        "                - Creates a `DataCollatorForSupervisedDataset` using the provided `tokenizer`.\n",
        "                - Returns a dictionary containing the training dataset, evaluation dataset (set to None), and the data collator.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary with the following keys:\n",
        "                - 'train_dataset': The initialized training dataset.\n",
        "                - 'eval_dataset': The evaluation dataset (currently set to None).\n",
        "                - 'data_collator': The data collator for batching the dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        train_dataset = SupervisedDataset(data_path, tokenizer = tokenizer, mode = mode)\n",
        "        data_collator = DataCollatorForSupervisedDataset(tokenizer = tokenizer)\n",
        "        return dict(train_dataset = train_dataset, eval_dataset = None, data_collator = data_collator)"
      ],
      "metadata": {
        "id": "C6uR6DRNSSOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `_tokenize_fn` function tokenizes a list of strings using a specified tokenizer. It takes two inputs: `strings`, which is a list of strings to tokenize, and `tokenizer`, a pre-trained tokenizer instance. The function tokenizes each string with padding set to the longest sequence and enables truncation to fit within the tokenizer's maximum length. It extracts the `input_ids`, which represent the tokenized strings, and sets the `labels` to the same values. Additionally, it calculates the lengths of the input and label sequences, excluding any padding. Finally, it returns a dictionary containing `input_ids`, `labels`, `input_ids_lens`, and `labels_lens`, effectively preparing the data for model training."
      ],
      "metadata": {
        "id": "EhjRq6GAYr9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _tokenize_fn(strings, tokenizer):\n",
        "\n",
        "            \"\"\"\n",
        "            Tokenize a list of strings using the provided tokenizer.\n",
        "\n",
        "            Input arguments:\n",
        "                strings (list of str):\n",
        "                    A list of input strings to be tokenized.\n",
        "\n",
        "                tokenizer (PreTrainedTokenizer):\n",
        "                    A tokenizer instance (e.g., from Hugging Face) that will tokenize the input strings.\n",
        "                    This tokenizer should return PyTorch tensors (`return_tensors=\"pt\"`).\n",
        "\n",
        "            What it does:\n",
        "                    - Tokenizes each string in the input `strings` list.\n",
        "                    - Applies padding to ensure all tokenized outputs are of the same length.\n",
        "                    - Truncates tokenized strings to fit within the tokenizer's maximum length.\n",
        "                    - Extracts input IDs and labels from the tokenized results.\n",
        "                    - Computes the length of each tokenized sequence (i.e., the number of non-padding tokens).\n",
        "\n",
        "            Returns:\n",
        "                dict: A dictionary with the following keys:\n",
        "                    - `input_ids` (list of torch.Tensor): The input token IDs for each string.\n",
        "                    - `labels` (list of torch.Tensor): The same as `input_ids`, used as labels.\n",
        "                    - `input_ids_lens` (list of int): Lengths of the input token sequences (excluding padding).\n",
        "                    - `labels_lens` (list of int): Lengths of the label token sequences (excluding padding).\n",
        "            \"\"\"\n",
        "\n",
        "            tokenized_list = [\n",
        "                tokenizer(\n",
        "                    text,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=\"longest\",\n",
        "                    #max_length=tokenizer.model_max_length,\n",
        "                    truncation=True,\n",
        "                )\n",
        "                for text in strings\n",
        "            ]\n",
        "            input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
        "            input_ids_lens = labels_lens = [\n",
        "                tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
        "            ]\n",
        "            return dict(\n",
        "                input_ids=input_ids,\n",
        "                labels=labels,\n",
        "                input_ids_lens=input_ids_lens,\n",
        "                labels_lens=labels_lens,\n",
        "            )"
      ],
      "metadata": {
        "id": "cuFvVfEu5Cyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this snippet, we set `data_path` to the file path `'data/code_alpaca_2k.json'`, which points to the dataset we want to use. Then, we create a data module by calling the `make_supervised_data_module` function, passing in the `data_path`, the previously defined `tokenizer`, and specifying the mode as `'IT'` for Instruction Tuning. This effectively initializes the training dataset and prepares the data for the supervised fine-tuning process, ensuring that the data is properly tokenized and ready for model training."
      ],
      "metadata": {
        "id": "WOLXTIGJrPjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path ='data/code_alpaca_2k.json'\n",
        "data_module = make_supervised_data_module(data_path, tokenizer=tokenizer, mode = 'IT')"
      ],
      "metadata": {
        "id": "D1KR3LNYk6wl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee472f89-2f71-4fa0-b88f-b71d49b05aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Formatting inputs...\n",
            "Tokenizing inputs... This may take some time...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: PEFT Configuration"
      ],
      "metadata": {
        "id": "i8NYIfo9qr8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we’re importing `LoraConfig` and `PeftModel` from the PEFT library. This library provides tools for parameter-efficient fine-tuning (PEFT), allowing us to efficiently adapt models to new tasks with minimal additional parameters. `LoraConfig` helps us configure the Low-Rank Adaptation (LoRA) method, which reduces the number of trainable parameters while maintaining model performance. Meanwhile, `PeftModel` is used to create a model that incorporates these adaptations, making it easier to fine-tune large language models effectively."
      ],
      "metadata": {
        "id": "KdJy57LTZgWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, PeftModel"
      ],
      "metadata": {
        "id": "je256ZOBune_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we define the configuration parameters for the LoRA setup: `lora_r`, `lora_alpha`, and `lora_dropout`.\n",
        "\n",
        "- **`lora_r`** is set to `2`, which specifies the rank for the low-rank adaptation. A lower rank typically means fewer parameters, helping to reduce computational costs while still capturing the essential information needed for the task. It is set to 2 here to demonstrate finetuning in colab in a shorter period of time.\n",
        "- **`lora_alpha`** is set to `16`, which is a scaling factor used to control the strength of the LoRA updates. A higher alpha can lead to stronger adaptations but may require careful tuning to avoid overfitting.\n",
        "- **`lora_dropout`** is set to `0.1`, indicating a dropout rate of 10%. This dropout is applied to the LoRA layers during training to help prevent overfitting by randomly dropping a portion of the parameters during updates."
      ],
      "metadata": {
        "id": "DbaOYizUZy7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_r = 2  # lora rank\n",
        "lora_alpha = 16  # alpha parameter for LoRA scaling\n",
        "lora_dropout = 0.1   # dropout rate for LoRA"
      ],
      "metadata": {
        "id": "dENAtaGOqxQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet sets up the PEFT (Parameter-Efficient Fine-Tuning) configuration for supervised fine-tuning of a causal language model using LoRA (Low-Rank Adaptation). The `LoraConfig` is initialized with previously defined variables: `lora_alpha`, `lora_dropout`, and `lora_r`, which control the scaling, dropout rate, and rank for LoRA, respectively. The `bias` is set to \"none\", and `task_type` is specified as \"CAUSAL_LM\" to indicate that the model is intended for causal language modeling tasks."
      ],
      "metadata": {
        "id": "AQs5n5zOZ9o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set supervised fine-tuning parameters\n",
        "peft_config = LoraConfig( lora_alpha = lora_alpha,\n",
        "                          lora_dropout = lora_dropout,\n",
        "                          r = lora_r,\n",
        "                          bias=\"none\",\n",
        "                          task_type=\"CAUSAL_LM\",\n",
        "                          )"
      ],
      "metadata": {
        "id": "Bk6RZxUTmX7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Huggingface Trainer Configuration"
      ],
      "metadata": {
        "id": "FoFGTOGYq3ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we import the necessary components to configure the training process using Hugging Face's `transformers` library and `trl`. The `TrainingArguments` class is used to define various training parameters such as learning rate, batch size, and the number of training epochs. The `SFTTrainer` class from the `trl` library is a specialized trainer designed for supervised fine-tuning (SFT) tasks, providing additional functionalities tailored for fine-tuning language models."
      ],
      "metadata": {
        "id": "LrVO-aHQaukj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "oQKFKmN_ZJ-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we define various training parameters for the supervised fine-tuning process. The `output_dir` specifies where to save the training results, while `num_train_epochs` sets the training duration to half an epoch. We disable mixed precision training with `fp16` and `bf16` set to `False`, opting for a batch size of 2 for both training and evaluation.\n",
        "\n",
        "`gradient_accumulation_steps` is set to 1 to apply gradients after each batch, and `gradient_checkpointing` is enabled to save memory during training. We limit the maximum gradient norm to 0.3 to prevent exploding gradients. The learning rate is adjusted to `2e-5`, lower than the default, with a weight decay of `0.01` to encourage regularization.\n",
        "\n",
        "The optimizer is set to `paged_adamw_8bit` to save memory and enhance training speed. The learning rate scheduler is fixed at a constant rate, and no specific maximum training steps are defined (`max_steps = -1`). We allocate a warm-up ratio of 0.03 for gradual learning rate increase, disable length grouping, and set logging intervals at every 25 steps. The sequence length is set to `None` to allow dynamic lengths, and packing is disabled. Finally, the `save_steps` parameter is set to a very high value to avoid saving intermediate results and thus conserve disk space."
      ],
      "metadata": {
        "id": "DA_yqNZnbKQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"./results\"\n",
        "num_train_epochs = 0.5\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 2\n",
        "per_device_eval_batch_size = 2\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-5   # default is 2e-4\n",
        "weight_decay = 0.01   # 0.001\n",
        "optim = 'paged_adamw_8bit'\n",
        "lr_scheduler_type = \"constant\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = False\n",
        "logging_steps = 25\n",
        "max_seq_length = None\n",
        "packing = False\n",
        "save_steps = 1000000 # not saving intermediate results to save disk space\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "# device_map = {\"\": \"cuda\"} # change to 'auto' on local machine"
      ],
      "metadata": {
        "id": "-ImoJ6shu9bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part sets up the training arguments for the Hugging Face Trainer using the previously defined variables. The `TrainingArguments` class allows you to specify essential parameters for training, such as the output directory, the number of epochs, batch sizes, optimization method, learning rate, and logging frequency."
      ],
      "metadata": {
        "id": "eE2EXeWgcNlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "              output_dir = output_dir,\n",
        "              num_train_epochs = num_train_epochs,\n",
        "              per_device_train_batch_size =per_device_train_batch_size,\n",
        "              gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "              optim = optim,\n",
        "              save_steps = save_steps,\n",
        "              logging_steps = logging_steps,\n",
        "              learning_rate = learning_rate,\n",
        "              weight_decay = weight_decay,\n",
        "              fp16 = fp16,\n",
        "              bf16 = bf16,\n",
        "              max_grad_norm = max_grad_norm,\n",
        "              max_steps = max_steps,\n",
        "              warmup_ratio = warmup_ratio,\n",
        "              group_by_length = group_by_length,\n",
        "              lr_scheduler_type = lr_scheduler_type\n",
        "              )"
      ],
      "metadata": {
        "id": "MrYS5W8CmhaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, the `SFTTrainer` is instantiated with the model and configurations set up earlier. The `model` parameter specifies which model to train, while `peft_config` applies the previously defined PEFT (Parameter-Efficient Fine-Tuning) settings. The `max_seq_length` controls the maximum length of input sequences, and `tokenizer` is the tokenizer used for processing the data. The `args` parameter includes all the training arguments defined previously. Additionally, `packing=True` allows for packing sequences of different lengths into the same batch, optimizing training efficiency. Finally, `**data_module` unpacks the training dataset and data collator into the trainer."
      ],
      "metadata": {
        "id": "b1R5rdZrcTSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "            model = model,\n",
        "            peft_config = peft_config,\n",
        "            max_seq_length = max_seq_length,\n",
        "            tokenizer = tokenizer,\n",
        "            args = training_arguments,\n",
        "            packing = True,\n",
        "            **data_module\n",
        "        )"
      ],
      "metadata": {
        "id": "YUXTDIVmmra9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Train and Merge"
      ],
      "metadata": {
        "id": "7bcCMzmAq9SG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `trainer.train()` function is then called to start the training process. This function handles the entire training loop, applying the defined training parameters, dataset, and model settings to fine-tune the model on the provided data."
      ],
      "metadata": {
        "id": "dJnp-JSLdRI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training model with the configurations mentioned...')\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CuB3XC_6m1JJ",
        "outputId": "75dbb5bf-3e37-4061-d4c5-edcc05007de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with the configurations mentioned...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='474' max='505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [474/505 45:08 < 02:57, 0.17 it/s, Epoch 0.47/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.889100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.758200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.679900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.461800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.646800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.442400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.502200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.496700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.564500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.506700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.395700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.442400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.454600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.408500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.370700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.456800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.431600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.464100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='505' max='505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [505/505 47:58, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.889100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.758200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.679900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.461800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.646800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.442400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.502200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.496700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.564500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.506700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.395700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.442400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.454600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.408500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.370700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.456800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.431600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.464100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.517500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.468800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=505, training_loss=0.5174135892698081, metrics={'train_runtime': 2885.3865, 'train_samples_per_second': 0.35, 'train_steps_per_second': 0.175, 'total_flos': 6878961086791680.0, 'train_loss': 0.5174135892698081, 'epoch': 0.5})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`trainer.save_model(output_dir)` saves the fine-tuned model to the specified `output_dir`."
      ],
      "metadata": {
        "id": "7khDklNxdela"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(output_dir)\n",
        "print('Model finetuned and saved to ', output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VunltqJGm1nF",
        "outputId": "5eb34215-a493-4457-dbd5-0e0b556f8adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model finetuned and saved to  ./results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code snippet, we are preparing to load and utilize the fine-tuned model. First, `base_model = LlamaForCausalLM.from_pretrained(model_name, return_dict=True, torch_dtype=torch.float16)` loads the base model with 16-bit floating-point precision for reduced memory usage and faster computation. Next, `model = PeftModel.from_pretrained(base_model, output_dir)` loads the fine-tuned model parameters from the specified `output_dir`. The `merge_and_unload()` method is then called to consolidate the model's parameters into a single structure. Finally, `tokenizer = CodeLlamaTokenizer.from_pretrained(output_dir)` loads the tokenizer associated with the fine-tuned model."
      ],
      "metadata": {
        "id": "zRvC11R5d3jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = LlamaForCausalLM.from_pretrained(model_name,\n",
        "                                              return_dict = True,\n",
        "                                              torch_dtype = torch.float16\n",
        "                                              )\n",
        "model = PeftModel.from_pretrained(base_model, output_dir)\n",
        "model = model.merge_and_unload()\n",
        "tokenizer = CodeLlamaTokenizer.from_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "30ae90ad4cb84c4eab612b0e0c6957e2",
            "11d0838619804d2db0cf7f45719c3715",
            "ad0a0bfd19284f4fad14c48aa539ed41",
            "d5ef6c0d5a184cbd8562481734ffb75e",
            "afcc32b8a2964f88bf9f46fd98e897b0",
            "5ef57b8d54e6488b9e8605ed07a62ce7",
            "309e5311ca124ce69d07ae10cbfadf25",
            "2756b2cf866d49d5be117298a91b222a",
            "a747096bb9064278a951a9e90905779d",
            "280308f9043943838f0cafae2adb22a3",
            "1e9aa593eb4b4275b27dd6c8f6df05d8"
          ]
        },
        "id": "VCCc72b8nRD7",
        "outputId": "75d0de39-6392-4e6d-caa3-269f985f58d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30ae90ad4cb84c4eab612b0e0c6957e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What it does:\n",
        " - Loads the base model using the specified `base_model_name`, configured for half-precision (`float16`).\n",
        " - Loads the fine-tuned model parameters from the specified directory using `PeftModel`.\n",
        " - Merges the base model and the fine-tuned model into a single model and unloads any unnecessary parts to save memory.\n",
        " - Loads the tokenizer corresponding to the fine-tuned model from the specified directory."
      ],
      "metadata": {
        "id": "TW8boFCXSYg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate code"
      ],
      "metadata": {
        "id": "D2iCZtPA2LRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `generate` function takes several inputs: a task identifier (`taskid`), a text prompt (`prompt`), the device for computation (`device`), the model for generating text (`model`), and the tokenizer for processing the text (`tokenizer`). It begins by tokenizing the input prompt using the tokenizer and prepares the model inputs on the specified device. The function logs the task ID for reference. Then, it generates text using the model with a greedy decoding strategy, specifying a maximum output length and using appropriate end-of-sequence and padding tokens. The raw generated output is decoded back into a string for readability. Before returning, it attempts to process the generated output using the `processOutput` function; if this processing fails, it defaults to returning the raw output. Finally, the function returns both the raw output and the processed output (or the raw output in case of an error)."
      ],
      "metadata": {
        "id": "txs-emZWUBYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def generate(taskid, prompt, device, model, tokenizer):\n",
        "\n",
        "        \"\"\"\n",
        "        Generate text from a prompt using the specified model and tokenizer.\n",
        "\n",
        "        Input arguments:\n",
        "            taskid (int):\n",
        "                An identifier for the task, used for printing and logging purposes.\n",
        "\n",
        "            prompt (str):\n",
        "                The input text prompt that the model will use to generate a response.\n",
        "\n",
        "            device (torch.device):\n",
        "                The device on which the model and tokenization operations will be performed (e.g., 'cpu' or 'cuda').\n",
        "\n",
        "            model (PreTrainedModel):\n",
        "                The language model used to generate text from the prompt.\n",
        "\n",
        "            tokenizer (PreTrainedTokenizer):\n",
        "                The tokenizer used to tokenize the prompt and decode the generated output.\n",
        "\n",
        "        What it does:\n",
        "                - Tokenizes the prompt using the provided `tokenizer`.\n",
        "                - Passes the tokenized prompt to the model for generating text with greedy decoding.\n",
        "                - Decodes the generated tokens back into text.\n",
        "                - Processes the generated output using the `processOutput` function to perform any additional processing.\n",
        "                - Logs the task ID and the generated text before and after processing.\n",
        "\n",
        "        Returns:\n",
        "            tuple:\n",
        "                - `output` (str): The raw text generated by the model.\n",
        "                - `after` (str): The processed output, after passing through the `processOutput` function.\n",
        "                If processing fails, `output` is returned as-is.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        model_inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
        "        print(\"Task ID: \" + str(taskid) + \"\\n\" + 100 * '-')\n",
        "\n",
        "\n",
        "        greedy_output = model.generate(model_inputs['input_ids'], max_length = 1000, eos_token_id=tokenizer.eos_token_id, pad_token_id = tokenizer.pad_token_id)\n",
        "        print(\"Generating...\")\n",
        "\n",
        "\n",
        "        output = tokenizer.decode(greedy_output[0])\n",
        "        print('Before processing\\n',output)\n",
        "\n",
        "        try:\n",
        "            after = processOutput(output)\n",
        "            print('After processing\\n', after)\n",
        "\n",
        "        except:\n",
        "            after = output\n",
        "            print('Could not process')\n",
        "\n",
        "        return output, after"
      ],
      "metadata": {
        "id": "0CYt6ImDUNNs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `processOutput` function takes a string (`output`) representing raw text generated by the language model, which often includes unwanted formatting and special tags. It first checks for specific starters indicating the beginning of the relevant response, and then it removes these starters along with special tags like `<s>` and `</s>`. The function replaces double quotes with single quotes, deletes any occurrence of the phrase \"Let's think step by step,\" and removes text enclosed in triple single quotes (''') as well as comments that start with hashtags (#). It identifies the positions of function definitions and return statements to determine if the generated code is complete. If there are more function definitions than return statements, it trims the code to ensure completeness. The function attempts to execute the cleaned code using the `exec` function. If execution fails, it checks for issues, such as incomplete return statements or additional lines after the last function, and further refines the output to return a more executable version. Ultimately, it returns the processed Python code, ready for execution."
      ],
      "metadata": {
        "id": "VWUjBRktelUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processOutput(output):\n",
        "\n",
        "        \"\"\"\n",
        "        Process the text generated by the language model to clean and prepare it for execution as Python code.\n",
        "\n",
        "        Input arguments:\n",
        "            output (str):\n",
        "                The raw, unprocessed text generated by the language model, often containing special tags, instructions, and formatting that need to be removed.\n",
        "\n",
        "        What it does:\n",
        "              - Removes special tags like `<s>` and `</s>`.\n",
        "              - Replaces double quotation marks (\") with single quotation marks (').\n",
        "              - Deletes the sentence \"Let's think step by step.\" if present.\n",
        "              - Removes instructions enclosed in triple single quotes (''') and comments starting with hashtags (#).\n",
        "              - Trims the code if it contains the line \"if __name__ == '__main__':\".\n",
        "              - If there are more function definitions (`def`) than return statements, it assumes incomplete code and removes the extra function.\n",
        "              - Attempts to execute the cleaned code. If execution fails, it further checks for issues like incomplete return statements or additional statements after a function and removes problematic lines.\n",
        "\n",
        "        Returns:\n",
        "            str: The processed and cleaned Python code ready for execution.\n",
        "                If errors are found during execution, attempts to clean up the code further and return a more executable version.\n",
        "        \"\"\"\n",
        "\n",
        "        possible_starters = ['### Response:', '### Output:']\n",
        "\n",
        "        for starter in possible_starters:\n",
        "            if(starter in output):\n",
        "                output = output[output.find(starter)+len(starter):]\n",
        "\n",
        "        output = output.replace('<s>','').replace('</s>','').strip()\n",
        "        output = output.replace('\"',\"'\")\n",
        "        output = output.replace('\\nLet\\'s think step by step.\\n\\n',\"\")\n",
        "        output = output.replace('Answer:',\"\")\n",
        "        output = remove_text_inside_quotes(output, \"'''\")\n",
        "        output = remove_lines_starting_with_hashtag(output)\n",
        "        deff = [m.start() for m in re.finditer(r\"def \",output)] # finds the occurrences of 'def'(the starting indices)\n",
        "        ret = [m.start() for m in re.finditer(r\"return\",output)] # finds the occurrences of 'return'(the starting indices)\n",
        "\n",
        "        if(\"'''\" in output):\n",
        "            output = output[:deff[len(deff)-1]]\n",
        "        if(\"if __name__ == '__main__':\" in output):\n",
        "            main = [m.start() for m in re.finditer(r\"if __name__ == '__main__':\",output)][0]\n",
        "            output = output[:main]\n",
        "\n",
        "        if (len(ret)==0):\n",
        "            return output\n",
        "\n",
        "        #if function starts but theres no return statement\n",
        "        if (ret[len(ret)-1] < deff[len(deff)-1]):\n",
        "            #print('funct not over!')\n",
        "            output = output[:deff[len(deff)-1]]\n",
        "\n",
        "        try:\n",
        "            #execute the output\n",
        "            exec(output)\n",
        "\n",
        "        except:\n",
        "            #Function starts and there is a return statement but there is a statement that doesn't end\n",
        "\n",
        "            last_return = ret[len(ret)-1]\n",
        "            try:\n",
        "                #there are additional statements after the end of the function\n",
        "                #sol : stop till the last return statement\n",
        "                end = last_return + [m.start() for m in re.finditer(\"\\n\",output[last_return:])][0]\n",
        "                output = output[:end]\n",
        "            except:\n",
        "                #the return statement is not complete\n",
        "                #sol : stop till before the last def line\n",
        "                output = output[:deff[len(deff)-1]]\n",
        "\n",
        "        return (output)"
      ],
      "metadata": {
        "id": "V3ofT_l04l_w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `remove_text_inside_quotes` function takes an input string and a specified type of quotation mark (e.g., single or double quotes) to remove all text enclosed within those quotation marks. It utilizes a regular expression pattern to identify the quoted sections and removes everything between the matching quotation marks, including the quotes themselves. The function returns the modified input string, which has all specified quoted sections removed."
      ],
      "metadata": {
        "id": "LM8Gslc0eumJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_text_inside_quotes( input_string, quote):\n",
        "\n",
        "        \"\"\"\n",
        "        Remove all text enclosed within a specified quote from the input string.\n",
        "\n",
        "        Input arguments:\n",
        "            input_string (str):\n",
        "                The input text which may contain quoted sections.\n",
        "            quote (str):\n",
        "                The type of quotation mark used to enclose the text you want to remove (e.g., single quote, double quote, triple quotes).\n",
        "\n",
        "        What it does:\n",
        "            - Utilizes a regular expression pattern to identify and remove all text found between pairs of the specified quotation mark (`quote`).\n",
        "            - Deletes everything between the matching quotation marks, including the quotes themselves.\n",
        "\n",
        "        Returns:\n",
        "            str: The input text with all sections enclosed by the specified quotes removed.\n",
        "        \"\"\"\n",
        "\n",
        "        exp = quote +'(.*?)' + quote\n",
        "        pattern = re.compile(exp, re.DOTALL)\n",
        "        result = re.sub(pattern, '', input_string)\n",
        "        return result"
      ],
      "metadata": {
        "id": "PfijfmrGU5QF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `remove_lines_starting_with_hashtag` function removes all lines from the input string that begin with a hashtag (#), which are typically used for comments. It splits the input string into individual lines, filters out any lines that start with a hashtag, and then joins the remaining lines back into a single string. The function returns the cleaned input string with all comment lines removed."
      ],
      "metadata": {
        "id": "v7XBvHz6e5e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_lines_starting_with_hashtag( input_string):\n",
        "\n",
        "        \"\"\"\n",
        "        Remove all lines from the input string that start with a hashtag (#).\n",
        "\n",
        "        Input arguments:\n",
        "            input_string (str):\n",
        "                The input text which may contain lines starting with a hashtag (#), typically comments.\n",
        "\n",
        "        What it does:\n",
        "            - Reads the input string line by line.\n",
        "            - Filters out any lines that start with a hashtag (#), commonly used for comments.\n",
        "            - Joins the remaining lines back into a single string.\n",
        "\n",
        "        Returns:\n",
        "            str: The input text with all lines starting with a hashtag removed.\n",
        "        \"\"\"\n",
        "\n",
        "        lines = input_string.split('\\n')\n",
        "        filtered_lines = [line for line in lines if not line.startswith('#')]\n",
        "        result_string = '\\n'.join(filtered_lines)\n",
        "        return result_string"
      ],
      "metadata": {
        "id": "0f5BMl5eUnqb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation - HumanEval & MBPP"
      ],
      "metadata": {
        "id": "iM-rOwxcmxxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Reference from the GitHub repository](https://github.com/openai/human-eval.git)"
      ],
      "metadata": {
        "id": "wV4P2GXce-l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "from collections import defaultdict, Counter\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from typing import List, Union, Iterable, Dict, Optional\n",
        "import itertools\n",
        "import os\n",
        "import gzip\n",
        "import json\n",
        "import contextlib\n",
        "import faulthandler\n",
        "import io\n",
        "import multiprocessing\n",
        "import platform\n",
        "import signal\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "class Evaluation:\n",
        "\n",
        "    def __init__(self):\n",
        "        # self.HUMAN_EVAL = \"eval/HumanEval.jsonl.gz\"\n",
        "        self.paths = {'humaneval': 'eval/human_eval.jsonl', 'mbpp': 'eval/mbpp.jsonl'}\n",
        "        # self.HUMAN_EVAL = '/content/Finetuning-CodeLlama/'\n",
        "\n",
        "    def read_problems(self, task):\n",
        "        evalset_file = self.paths[task]\n",
        "        return {task[\"task_id\"]: task for task in self.stream_jsonl(evalset_file)}\n",
        "\n",
        "    def stream_jsonl(self, filename: str) -> Iterable[Dict]:\n",
        "        if filename.endswith(\".gz\"):\n",
        "            with gzip.open(filename, \"rt\") as fp:\n",
        "                for line in fp:\n",
        "                    if any(not x.isspace() for x in line):\n",
        "                        yield json.loads(line)\n",
        "        else:\n",
        "            with open(filename, \"r\") as fp:\n",
        "                for line in fp:\n",
        "                    if any(not x.isspace() for x in line):\n",
        "                        yield json.loads(line)\n",
        "\n",
        "    def write_jsonl(self, filename: str, data: Iterable[Dict], append: bool = False):\n",
        "        mode = 'ab' if append else 'wb'\n",
        "        filename = os.path.expanduser(filename)\n",
        "        with gzip.open(filename, mode) if filename.endswith(\".gz\") else open(filename, mode) as fp:\n",
        "            for x in data:\n",
        "                fp.write((json.dumps(x) + \"\\n\").encode('utf-8'))\n",
        "\n",
        "    def estimate_pass_at_k(self,\n",
        "        num_samples: Union[int, List[int], np.ndarray],\n",
        "        num_correct: Union[List[int], np.ndarray],\n",
        "        k: int\n",
        "    ) -> np.ndarray:\n",
        "        def estimator(n: int, c: int, k: int) -> float:\n",
        "            if n - c < k:\n",
        "                return 1.0\n",
        "            return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
        "\n",
        "        if isinstance(num_samples, int):\n",
        "            num_samples_it = itertools.repeat(num_samples, len(num_correct))\n",
        "        else:\n",
        "            num_samples_it = iter(num_samples)\n",
        "\n",
        "        return np.array([estimator(int(n), int(c), k) for n, c in zip(num_samples_it, num_correct)])\n",
        "\n",
        "    def evaluate_functional_correctness_for_n_tasks(\n",
        "        self,\n",
        "        sample_file: str,\n",
        "        task,\n",
        "        k: List[int] = [1, 2, 10, 100],\n",
        "        n_workers: int = 4,\n",
        "        timeout: float = 3.0,\n",
        "    ):\n",
        "\n",
        "        problems = self.read_problems(task = task)\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
        "            futures = []\n",
        "            completion_id = Counter()\n",
        "            n_samples = 0\n",
        "            results = defaultdict(list)\n",
        "\n",
        "            print(\"Reading samples...\")\n",
        "            for sample in tqdm.tqdm(self.stream_jsonl(sample_file)):\n",
        "                task_id = sample[\"task_id\"]\n",
        "                completion = sample[\"completion\"]\n",
        "                args = (problems[task_id], completion, timeout, completion_id[task_id])\n",
        "                future = executor.submit(self.check_correctness, *args)\n",
        "                futures.append(future)\n",
        "                completion_id[task_id] += 1\n",
        "                n_samples += 1\n",
        "\n",
        "            print(\"Running test suites...\")\n",
        "            for future in tqdm.tqdm(as_completed(futures), total=len(futures)):\n",
        "                result = future.result()\n",
        "                results[result[\"task_id\"]].append((result[\"completion_id\"], result))\n",
        "\n",
        "        total, correct = [], []\n",
        "        for result in results.values():\n",
        "            result.sort()\n",
        "            passed = [r[1][\"passed\"] for r in result]\n",
        "            total.append(len(passed))\n",
        "            correct.append(sum(passed))\n",
        "        total = np.array(total)\n",
        "        correct = np.array(correct)\n",
        "\n",
        "        pass_at_k = {f\"pass@{k}\": self.estimate_pass_at_k(total, correct, k).mean()\n",
        "                     for k in k if (total >= k).all()}\n",
        "\n",
        "        def combine_results():\n",
        "            for sample in self.stream_jsonl(sample_file):\n",
        "                task_id = sample[\"task_id\"]\n",
        "                result = results[task_id].pop(0)\n",
        "                sample['task'] = problems[task_id]\n",
        "                sample[\"result\"] = result[1][\"result\"]\n",
        "                sample[\"passed\"] = result[1][\"passed\"]\n",
        "                yield sample\n",
        "\n",
        "        out_file = sample_file + \"_results.jsonl\"\n",
        "        print(f\"Writing results to {out_file}...\")\n",
        "        self.write_jsonl(out_file, tqdm.tqdm(combine_results(), total=n_samples))\n",
        "\n",
        "        return pass_at_k, pass_at_k[list(pass_at_k.keys())[0]] * 100\n",
        "\n",
        "    def check_correctness(self, problem: Dict, completion: str, timeout: float,\n",
        "                          completion_id: Optional[int] = None) -> Dict:\n",
        "        def unsafe_execute():\n",
        "            with self.create_tempdir():\n",
        "                self.reliability_guard()\n",
        "\n",
        "                check_program = (\n",
        "                      problem[\"test\"] + \"\\n\" +\n",
        "                      problem[\"prompt\"] + completion + \"\\n\" +\n",
        "                      f\"check({problem['entry_point']})\"\n",
        "                  )\n",
        "\n",
        "                try:\n",
        "                    exec_globals = {}\n",
        "                    with self.swallow_io():\n",
        "                        with self.time_limit(timeout):\n",
        "                            exec(check_program, exec_globals)\n",
        "                    result.append(\"passed\")\n",
        "                except TimeoutException:\n",
        "                    result.append(\"timed out\")\n",
        "                except BaseException as e:\n",
        "                    result.append(f\"failed: {e}\")\n",
        "\n",
        "        manager = multiprocessing.Manager()\n",
        "        result = manager.list()\n",
        "\n",
        "        p = multiprocessing.Process(target=unsafe_execute)\n",
        "        p.start()\n",
        "        p.join(timeout=timeout + 1)\n",
        "        if p.is_alive():\n",
        "            p.kill()\n",
        "\n",
        "        if not result:\n",
        "            result.append(\"timed out\")\n",
        "\n",
        "        return dict(\n",
        "            task_id=problem[\"task_id\"],\n",
        "            passed=result[0] == \"passed\",\n",
        "            result=result[0],\n",
        "            completion_id=completion_id,\n",
        "        )\n",
        "\n",
        "    @contextlib.contextmanager\n",
        "    def time_limit(self, seconds: float):\n",
        "        def signal_handler(signum, frame):\n",
        "            raise TimeoutException(\"Timed out!\")\n",
        "        signal.signal(signal.SIGALRM, signal_handler)\n",
        "        signal.setitimer(signal.ITIMER_REAL, seconds)\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            signal.setitimer(signal.ITIMER_REAL, 0)\n",
        "\n",
        "    @contextlib.contextmanager\n",
        "    def swallow_io(self):\n",
        "        stream = self.WriteOnlyStringIO()\n",
        "        with contextlib.redirect_stdout(stream):\n",
        "            with contextlib.redirect_stderr(stream):\n",
        "                with self.redirect_stdin(stream):\n",
        "                    yield\n",
        "\n",
        "    @contextlib.contextmanager\n",
        "    def create_tempdir(self):\n",
        "        with tempfile.TemporaryDirectory() as dirname:\n",
        "            with self.chdir(dirname):\n",
        "                yield dirname\n",
        "\n",
        "    class TimeoutException(Exception):\n",
        "        pass\n",
        "\n",
        "    class WriteOnlyStringIO(io.StringIO):\n",
        "        def read(self, *args, **kwargs):\n",
        "            raise IOError\n",
        "\n",
        "        def readline(self, *args, **kwargs):\n",
        "            raise IOError\n",
        "\n",
        "        def readable(self, *args, **kwargs):\n",
        "            return False\n",
        "\n",
        "    class redirect_stdin(contextlib._RedirectStream):\n",
        "        _stream = 'stdin'\n",
        "\n",
        "    @contextlib.contextmanager\n",
        "    def chdir(self, root):\n",
        "        cwd = os.getcwd()\n",
        "        os.chdir(root)\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            os.chdir(cwd)\n",
        "\n",
        "    def reliability_guard(self, maximum_memory_bytes: Optional[int] = None):\n",
        "\n",
        "        if maximum_memory_bytes is not None:\n",
        "            import resource\n",
        "            resource.setrlimit(resource.RLIMIT_AS, (maximum_memory_bytes, maximum_memory_bytes))\n",
        "            resource.setrlimit(resource.RLIMIT_DATA, (maximum_memory_bytes, maximum_memory_bytes))\n",
        "            if platform.uname().system != 'Darwin':\n",
        "                resource.setrlimit(resource.RLIMIT_STACK, (maximum_memory_bytes, maximum_memory_bytes))\n",
        "\n",
        "        faulthandler.disable()\n",
        "\n",
        "        import builtins\n",
        "        builtins.exit = None\n",
        "        builtins.quit = None\n",
        "\n",
        "        import os\n",
        "        os.environ['OMP_NUM_THREADS'] = '1'\n",
        "\n",
        "        os.kill = None\n",
        "        os.system = None\n",
        "\n",
        "        import shutil\n",
        "        shutil.rmtree = None\n",
        "        shutil.move = None\n",
        "\n",
        "        import subprocess\n",
        "        subprocess.Popen = None\n",
        "\n",
        "        if isinstance(__builtins__, dict):\n",
        "            __builtins__['help'] = None\n",
        "        else:\n",
        "            builtins.help = None"
      ],
      "metadata": {
        "id": "mb6q2yW-PuOd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the prompts for evaluation"
      ],
      "metadata": {
        "id": "a4lnmaz6ZrsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generates a formatted instruction prompt based on the specified dataset type. If the dataset is CodeAlpaca, it takes a problem statement as input and instructs the model to create a Python script based on that statement. For the LeetCode dataset, it extracts the question and function header from the input, instructing the model to write Python code for the specified problem while clearly separating the input and expected output."
      ],
      "metadata": {
        "id": "Pp4SAlOagSVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_alpaca_prompt(input):\n",
        "\n",
        "            \"\"\"\n",
        "            Generates a formatted instruction prompt based on the CodeAlpaca dataset.\n",
        "\n",
        "            Input arguments:\n",
        "                input (str): The problem statement or task for which the Python script is to be created.\n",
        "\n",
        "            What it does:\n",
        "                Constructs a prompt in a specific format that includes the instruction to create a Python script\n",
        "                based on the provided input problem statement. The prompt is designed to guide the model in generating\n",
        "                a relevant response.\n",
        "\n",
        "            Returns:\n",
        "                str: A formatted instruction prompt for a model trained on the CodeAlpaca dataset.\n",
        "            \"\"\"\n",
        "\n",
        "            INSTRUCTION = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "\n",
        "            ### Instruction:\n",
        "            Create a Python script for this problem:\n",
        "            {input}\n",
        "\n",
        "            ### Response:\"\"\"\n",
        "\n",
        "            return INSTRUCTION\n",
        "\n",
        "\n",
        "def generate_leetcode_prompt(input):\n",
        "\n",
        "        \"\"\"\n",
        "            Generates a formatted instruction prompt based on the leetcode dataset.\n",
        "\n",
        "            Input arguments:\n",
        "                input (str): The problem statement or task for which the Python script is to be created.\n",
        "\n",
        "            What it does:\n",
        "                Constructs a prompt in a specific format that includes the instruction to create a Python script\n",
        "                based on the provided input problem statement. The prompt is designed to guide the model in generating\n",
        "                a relevant response.\n",
        "\n",
        "            Returns:\n",
        "                str: A formatted instruction prompt for a model trained on the leetcode dataset.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            ques = input[input.find('\"\"\"')+3:]\n",
        "        except:\n",
        "            ques = input[input.find(\"'''\")+3:]\n",
        "\n",
        "        func_header =  input[:input.find(\"'''\")]\n",
        "        INSTRUCTION = f\"\"\"Write a response that appropriately completes the request.\n",
        "\n",
        "\n",
        "                    ### Input:\n",
        "                    Write python code for this problem:\n",
        "                    {ques}\n",
        "\n",
        "                    ### Output: \\n{func_header.split('(')[0]}\"\"\"\n",
        "\n",
        "        return INSTRUCTION"
      ],
      "metadata": {
        "id": "iHiPszgFWJv9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = {'alpaca' : generate_alpaca_prompt, 'leetcode': generate_leetcode_prompt}"
      ],
      "metadata": {
        "id": "2Dae9aywZWMm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the evaluation"
      ],
      "metadata": {
        "id": "4raUD9PgZz5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function generates outputs for all problems in the HumanEval dataset using the specified language model and tokenizer. It reads the problems and, based on the given `prompt_type` (e.g., 'alpaca' or 'leetcode'), generates responses by calling the `generate` function. The results are stored in a list of dictionaries containing the task ID, full generation, and completion. Finally, the samples are saved to a JSONL file named \"samples.jsonl\". If no prompt type is provided, it defaults to using the standard prompt for each problem."
      ],
      "metadata": {
        "id": "KzdSHNyKgoR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to run all the problems\n",
        "def get_outputs(model, tokenizer, device, tasks = ['humaneval'], prompt_type = None, num_samples_per_task = 1):\n",
        "\n",
        "        \"\"\"\n",
        "        Reads all the problems from the HumanEval dataset and generates outputs using the specified model and tokenizer.\n",
        "\n",
        "        Input arguments:\n",
        "            model: The language model to be used for generating outputs.\n",
        "            tokenizer: The tokenizer associated with the model.\n",
        "            device: The device on which the model is to be executed (e.g., 'cuda' or 'cpu').\n",
        "            prompt_type (str, optional): The type of prompt to use (e.g., 'alpaca' or 'leetcode'). Defaults to None.\n",
        "            num_samples_per_task (int, optional): The number of samples to generate for each task. Defaults to 1.\n",
        "\n",
        "        What it does:\n",
        "            1. Reads all problems from the HumanEval dataset.\n",
        "            2. Generates outputs for each problem using the specified model and tokenizer.\n",
        "            3. Supports different types of prompts based on the provided `prompt_type`.\n",
        "            4. Creates a list of dictionaries in the format [{task_id: generation}, ...].\n",
        "            5. Writes the generated outputs to a JSONL file named \"samples.jsonl\".\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        eval = Evaluation()\n",
        "\n",
        "        for task in tasks:\n",
        "\n",
        "          problems = eval.read_problems(task = task)\n",
        "          samples = []\n",
        "          if(prompt_type == None):\n",
        "\n",
        "              for task_id in problems:\n",
        "\n",
        "                  full, completion = generate(task_id, problems[task_id][\"prompt\"], device, model, tokenizer)\n",
        "                  samples.append(dict(task_id=task_id, full_generation = full, completion = completion))\n",
        "\n",
        "          else:\n",
        "\n",
        "              for task_id in problems:\n",
        "\n",
        "                  full, completion = generate(task_id, prompts[prompt_type](input = problems[task_id][\"prompt\"]), device, model, tokenizer)\n",
        "                  samples.append(dict(task_id=task_id, full_generation = full, completion = completion))\n",
        "\n",
        "          eval.write_jsonl(task + \"_results.jsonl\", samples)"
      ],
      "metadata": {
        "id": "-LpkiVK-ZFto"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function runs the specified number of tests on the HumanEval dataset using a given language model and tokenizer. It reads the problems and selects the first `num_of_tests` entries."
      ],
      "metadata": {
        "id": "-3QlXSe5g7AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to run the first n tests\n",
        "def get_outputs_for_first_n_tests(model, tokenizer, device, tasks = ['humaneval'], prompt_type = None, num_of_tests = 1, num_samples_per_task = 1):\n",
        "\n",
        "        \"\"\"\n",
        "        Runs the first n tests on the provided model and tokenizer and generates outputs.\n",
        "\n",
        "        Input arguments:\n",
        "            model: The language model to be used for generating outputs.\n",
        "            tokenizer: The tokenizer associated with the model.\n",
        "            device: The device on which the model is to be executed (e.g., 'cuda' or 'cpu').\n",
        "            prompt_type (str, optional): The type of prompt to use (e.g., 'alpaca' or 'leetcode'). Defaults to None.\n",
        "            num_of_tests (int, optional): The number of tests to run. Defaults to 1.\n",
        "            num_samples_per_task (int, optional): The number of samples to generate for each task. Defaults to 1.\n",
        "\n",
        "        What it does:\n",
        "            - Reads problems from the HumanEval dataset.\n",
        "            - Collects the specified number of problems for testing.\n",
        "            - Generates outputs for the selected problems using the specified model and tokenizer.\n",
        "            - Supports different types of prompts based on the provided `prompt_type`.\n",
        "            - Writes the generated outputs to a JSONL file named \"samples.jsonl\".\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "\n",
        "        eval = Evaluation()\n",
        "        for task in tasks:\n",
        "\n",
        "          problems = eval.read_problems(task = task)\n",
        "          probs = {}\n",
        "          n = 0\n",
        "          for key, value in problems.items():\n",
        "              if(n < num_of_tests):\n",
        "                  probs[key] = value\n",
        "              n = n + 1\n",
        "\n",
        "          samples = []\n",
        "          if(prompt_type == None):\n",
        "\n",
        "              for task_id in probs:\n",
        "                  full, completion = generate(task_id, problems[task_id][\"prompt\"], device, model, tokenizer)\n",
        "                  samples.append(dict(task_id=task_id, full_generation = full, completion = completion))\n",
        "\n",
        "          else:\n",
        "\n",
        "              for task_id in probs:\n",
        "                  full, completion = generate(task_id, prompts[prompt_type](input = problems[task_id][\"prompt\"]), device, model, tokenizer)\n",
        "                  samples.append(dict(task_id=task_id, full_generation = full, completion = completion))\n",
        "\n",
        "          eval.write_jsonl(task + \"_results.jsonl\", samples)"
      ],
      "metadata": {
        "id": "GaIUpHZ0ZCNJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function call generates outputs for the first test in the HumanEval dataset using the specified language model and tokenizer. The `device` is set to 'cuda' to utilize a GPU for computation. The `prompt_type` is set to 'leetcode', which means the function will format the prompts accordingly. The function will generate one sample for the specified test. This output will then be written to a JSONL file."
      ],
      "metadata": {
        "id": "Fl_3WUBrhWCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = ['humaneval', 'mbpp']"
      ],
      "metadata": {
        "id": "PJcvG2fbly6B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_outputs_for_first_n_tests(model, tokenizer, tasks = tasks, device = 'cuda', num_of_tests = 1, prompt_type = 'leetcode', num_samples_per_task = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sha1cyFhZ5TJ",
        "outputId": "0a468ea5-3add-432f-e280-c116e4be4c41",
        "collapsed": true
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task ID: HumanEval/0\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating...\n",
            "Before processing\n",
            " <s> Write a response that appropriately completes the request.\n",
            "\n",
            "\n",
            "                    ### Input:\n",
            "                    Write python code for this problem:\n",
            "                     Check if in given list of numbers, are any two numbers closer to each other than\n",
            "    given threshold.\n",
            "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
            "    False\n",
            "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
            "    True\n",
            "    \"\"\"\n",
            "\n",
            "\n",
            "                    ### Output: \n",
            "from typing import List\n",
            "\n",
            "\n",
            "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
            "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
            "    given threshold.\n",
            "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
            "    False\n",
            "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
            "    True\n",
            "    \"\"\"\n",
            "    for i in range(len(numbers)):\n",
            "        for j in range(i + 1, len(numbers)):\n",
            "            if abs(numbers[i] - numbers[j]) < threshold:\n",
            "                return True\n",
            "    return False\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    import doctest\n",
            "\n",
            "    doctest.testmod()\n",
            "</s>\n",
            "After processing\n",
            " from typing import List\n",
            "\n",
            "\n",
            "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
            "    \n",
            "    for i in range(len(numbers)):\n",
            "        for j in range(i + 1, len(numbers)):\n",
            "            if abs(numbers[i] - numbers[j]) < threshold:\n",
            "                return True\n",
            "    return False\n",
            "\n",
            "\n",
            "\n",
            "Task ID: MBPP/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Generating...\n",
            "Before processing\n",
            " <s> Write a response that appropriately completes the request.\n",
            "\n",
            "\n",
            "                    ### Input:\n",
            "                    Write python code for this problem:\n",
            "                    f min_cost(): \n",
            "\n",
            "    '''Write a function to find the minimum cost path to reach (m, n) from (0, 0) for the given cost matrix cost[][] and a position (m, n) in cost[][].'''\n",
            "\n",
            "    \n",
            "\n",
            "                    ### Output: \n",
            "def min_cost(): \n",
            "\n",
            "    \n",
            "\n",
            "                    ### Solution:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "After processing\n",
            " def min_cost(): \n",
            "\n",
            "    \n",
            "\n",
            "                    ### Solution:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Pass@k"
      ],
      "metadata": {
        "id": "sFdYoYi1ayMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code initializes the `HumanEval` class and evaluates the functional correctness of the generated outputs stored in the \"samples.jsonl\" file. The `evaluate_functional_correctness_for_n_tasks` method returns two metrics: `pass_at_k`, which indicates the number of tasks that passed the correctness test at a specified threshold, and `accuracy`, representing the proportion of correct outputs among the evaluated tasks."
      ],
      "metadata": {
        "id": "o35O2oMnhLjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval = Evaluation()\n",
        "for task in tasks:\n",
        "  pass_at_k, accuracy = eval.evaluate_functional_correctness_for_n_tasks(task + \"_results.jsonl\", task = task)\n",
        "  print(f\"\\nThe pass@1 for task {task}: {pass_at_k}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaIlU1M8mFs0",
        "outputId": "9d61530b-7987-4dba-c258-2757934caaa0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00, 1532.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running test suites...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  9.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing results to humaneval_results.jsonl_results.jsonl...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 2063.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The pass@1 for task humaneval: {'pass@1': 1.0}\n",
            "Reading samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00, 1772.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running test suites...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]Process Process-36:\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-45-4d6177abbec1>\", line 141, in unsafe_execute\n",
            "    exec(check_program, exec_globals)\n",
            "  File \"<string>\", line 22\n",
            "    check(min_cost)\n",
            "IndentationError: expected an indented block after function definition on line 17\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-45-4d6177abbec1>\", line 143, in unsafe_execute\n",
            "    except TimeoutException:\n",
            "NameError: name 'TimeoutException' is not defined\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing results to mbpp_results.jsonl_results.jsonl...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1080.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The pass@1 for task mbpp: {'pass@1': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}